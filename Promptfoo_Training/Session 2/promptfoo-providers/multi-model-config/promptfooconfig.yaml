# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

description: "Rubik's Cube Tutorial Eval"

providers:
  - id: openai:gpt-4.1
    config:
      temperature: 0.7
      max_tokens: 150
  - id: openai:gpt-4o-mini
    config:
      temperature: 1
  - id: anthropic:messages:claude-sonnet-4-20250514
    config:
      temperature: 1
  - id: openai:qwen3-1.7b
    config:
      apiBaseUrl: http://localhost:1234/v1
      apiKey: lmstudio
      model: qwen3-1.7b
      temperature: 0.7
      max_tokens: 300

prompts:
  - "Can you teach me how to solve a Rubik's cube?"

tests:
  - vars: {}
    assert:
      - type: javascript
        value: "output.toLowerCase().includes('rubik')"
      - type: javascript
        value: "output.toLowerCase().includes('cube')"

assertions:
  - type: model-graded-assertion
    name: "Factuality"
    provider: openai:gpt-4o-mini
    criteria: "Is the explanation accurate and free from hallucinated or incorrect steps?"
    threshold: 0.85

  - type: model-graded-assertion
    name: "LLM Rubric"
    provider: openai:gpt-4o
    criteria: >
      Evaluate the overall helpfulness, clarity, and educational value of the explanation.
      Consider structure, accuracy, and completeness in teaching Rubikâ€™s Cube solving.
    threshold: 0.9

  - type: model-graded-assertion
    name: "Answer Relevance"
    provider: anthropic:claude-sonnet-4
    criteria: "Does the response directly and thoroughly address how to solve a Rubik's cube?"
    threshold: 0.8
