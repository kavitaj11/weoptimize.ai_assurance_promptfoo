# Session 3: Red Teaming LLMs (weOptimize Practice)

This session explores adversarial testing (red teaming) for LLMs using practical scenarios and challenge prompts. You will:

- Learn about prompt injection and adversarial attacks
- Practice with real-world red teaming challenges
- Use Promptfoo and other tools to evaluate model robustness

## Structure
- `LLM-red-teaming/` — Red teaming challenge prompts and configs
- `weOptimize-ai-red-teaming-practice/` — Practice scenarios and solutions
- `session3_promptfoo_testresults/` — Output folder for HTML results

## Getting Started
1. Review the challenge and practice folders for prompts and configs.
2. Install dependencies:
   ```sh
   pip install promptfoo openai
   ```
3. Set your API key as an environment variable:
   ```sh
   export OPENAI_API_KEY=your-key-here
   ```
4. Run Promptfoo tests or use provided scripts for batch evaluation.

---
This session builds skills in adversarial LLM evaluation and prompt security testing.
